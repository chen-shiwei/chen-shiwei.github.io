---
title: "数据密集型应用设计"
date: "2021-03-09"
tag: ["数据密集型应用设计","book"]
categories: ["数据密集型应用设计","book"]
draft: true
---
# 第六章 分区

## 1. 为什么分区

- 主要为了可伸缩性
- 将查询和负载均匀的分布在每一个节点上，避免热点

## 2.怎么分区

- 键值数据的分区

  - **根据键的范围分区**
    - 好处 
      - 顺序键保存
      - **范围扫描简单效率高**
      - 类似sstable、lsm tree
    - 缺点
      - **有热点问题**
      - 如果根据时间范围分区，每天一个分区，那么写入都会在同一分区，可以时间戳加上其他区分方式，再细分
      -  在这种方法中，当分区变得太大时，通常将分区分成两个子分区，动态地再平衡分区。
  - **根据键的散列分区**
  - 处于分区目的散列函数不需要太强大
      - Cassandra和MongoDB使用MD5
      - Voldemort使用Fowler-Noll-Vo函数
    - **可以均匀分布，减少热点**
    - **会失去范围查询**
    - Cassandra采取了折衷的策略，使用由多个列组成的复合主键来声明
    - 键中只有第一列会作为散列的依据，而其他列则被用作Casssandra的SSTables中排序数据的连接索引
  - **两种方法搭配使用也是可行的，例如使用复合主键：使用键的一部分来标识分区，而使用另一部分作为排序顺序。**
- 消除热点、负载倾斜
  - 在社交媒体网站上，一个拥有数百万追随者的名人用户在做某事时可能会引发一场风暴【14】。这个事件可能导致大量写入同一个键（键可能是名人的用户ID，或者人们正在评论的动作的ID）。哈希策略不起作用，因为两个相同ID的哈希值仍然是相同的
  - 如果一个主键被认为是非常火爆的，一个简单的方法是在主键的开始或结尾添加一个随机数。只要一个两位数的十进制随机数就可以将主键分散为100种不同的主键,从而存储在不同的分区中。
  -  然而，将主键进行分割之后，任何读取都必须要做额外的工作，因为他们必须从所有100个主键分布中读取数据并将其合并。此技术还需要额外的记录：只需要对少量热点附加随机数；对于写入吞吐量低的绝大多数主键来说是不必要的开销。因此，您还需要一些方法来跟踪哪些键需要被分割。

## 3. 分区和次级索引

### 3.1二级索引对数据库进行分区

- 基于文档的分区 document-based
- ![image](/img/ddia-5-1.png)
- 在这种索引方法中，每个分区是完全独立的：每个分区维护自己的二级索引，仅覆盖该分区中的文档。它不关心存储在其他分区的数据。无论何时您需要写入数据库（添加，删除或更新文档），只需处理包含您正在编写的文档ID的分区即可。出于这个原因，**文档分区索引**也被称为**本地索引（local index）**
	- 相关数据库
  - MongoDB
	  - Elasticsearch
	  - Riak
	  - Cassndra
	  - SolrCould
	  - VoltDB
	
- 基于关键词的分区 term-based

  - ![image](/img/ddia-5-1.png)
  - 来自所有分区的红色汽车在红色索引中，并且索引是分区的，首字母从`a`到`r`的颜色在分区0中，`s`到`z`的在分区1。汽车制造商的索引也与之类似（分区边界在`f`和`h`之间）
  - 关键词分区的全局索引优于文档分区索引的地方点是它可以使读取更有效率：不需要**分散/收集**所有分区，客户端只需要向包含关键词的分区发出请求

## 4.分区再平衡

### 4.1需要平衡的原因

- 查询吞吐量增加，添加cpu
- 数据集大小增加，增加磁盘和内存
- 机器故障

需要将请求和数据从节点迁移新节点

将负载从集群中的一个节点向另一个节点移动的过程称为**再平衡（rebalancing）**

### 4.2 平衡策略

- Hash mod n(不建议 反面)
  - `hash(key) mod 10`会返回一个介于0和9之间的数字，数据均匀分布在0-9节点中，如果节点增加减少迁移数据量过大
- 固定数量分区
  - Redis Cluster包含了16384个哈希槽，每个Key通过计算后都会落在具体一个槽位上，而这个槽位是属于哪个存储节点的，则由用户自己定义分配。
  - redis cluster 对于槽位的转移和分派，Redis集群是不会自动进行的，而是需要人工配置的。所以Redis集群的高可用是依赖于节点的主从复制与主从间的自动故障转移
  - 通过为更强大的节点分配更多的分区，可以强制这些节点承载更多的负载。在Riak 【15】，Elasticsearch 【24】，Couchbase 【10】和Voldemort 【25】中使用了这种再平衡的方法。

### 4.3 再平衡之后，数据进行了节点间迁移，怎么正确路由客户端请求正确节点。

**服务发现**
- ZooKeeper
  - Espresso
  - HBase
  - SolrCould
  - Kafka
- Etcd
- Gossip
  - Redis Cluster
  - Cassandra
  - Riak



